{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPENDENCIES\n",
    "#######################################################################################################################\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from functions_object_detection import *\n",
    "from functions_line_detection import *\n",
    "from config.tesseract import path_to_my_tesseract\n",
    "from functions_word_detection import *\n",
    "from functions_char_detection import *\n",
    "from cut_to_characters import *\n",
    "from utils.util_miscellaneous import changeDirectory\n",
    "\n",
    "#dont require pip\n",
    "import os\n",
    "import shutil\n",
    "import string\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#require pip\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "######################################################################################################################################\n",
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "pytesseract.pytesseract.tesseract_cmd = path_to_my_tesseract\n",
    "#custom_config = r'--oem 3 --psm 6'\n",
    "custom_config = r'-l por+eng --psm 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "parent_directory = os.path.abspath('')\n",
    "root = os.path.abspath(os.path.join(parent_directory, os.pardir))\n",
    "\n",
    "data_input_folder = os.path.join(root, 'test', 'data', 'input')\n",
    "data_output_folder = os.path.join(root, 'test', 'data', 'output')\n",
    "\n",
    "\n",
    "#clean and create paths to save images after preprocessing\n",
    "create_path(os.path.join(data_output_folder, 'filtered', 'output_all_br')) #source image preprocessing output with blured backround to compare\n",
    "create_path(os.path.join(data_output_folder, 'filtered', 'output_all')) #source image preprocessing output ready to exctract objects and lines\n",
    "create_path(os.path.join(data_output_folder, 'recognition')) # extracted objects, lines, and classification results\n",
    "\n",
    "\n",
    "#read all the source images for recognition\n",
    "#sourcepath='.\\\\data\\\\\\\\'\n",
    "sourcepath=data_input_folder\n",
    "photos = [f for f in listdir(sourcepath) if isfile(join(sourcepath, f))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_001.png\n",
      "path_objs c:\\Users\\JosePombo\\Desktop\\repos\\ocr\\test\\data\\output\\recognition\\objects\\ex_001.png\\ \\\n",
      "written done\n",
      "(455, 58)\n",
      "line image 0\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1063\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 0\n",
      "line image 1\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1062\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 1\n",
      "line image 2\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1061\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 23, 28]]]\n",
      "key is 2\n",
      "line image 3\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1062\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 3\n",
      "line image 4\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1061\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 23, 28]]]\n",
      "key is 4\n",
      "line image 5\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1060\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 5\n",
      "line image 6\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1059\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 6\n",
      "line image 7\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1058\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 7\n",
      "line image 8\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1057\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 8\n",
      "line image 9\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1056\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 9\n",
      "line image 10\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1055\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 10\n",
      "line image 11\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 15]\n",
      "line detection pixels [[0, 15]]\n",
      "1054\n",
      "pixels line [0, 15]\n",
      "[letter_pixels] [[[0, 15, 5, 10], [0, 15, 10, 16], [0, 15, 16, 22], [0, 15, 22, 28]]]\n",
      "key is 11\n",
      "line image 12\n",
      "Base Image\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<line_detection>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<\n",
      "gonna add pixels to line_pixel -> [0, 16]\n",
      "line detection pixels [[0, 16]]\n",
      "|. Ord\n",
      "object initial coordinates 8 15\n",
      "level 1 merge detection- goes  up 9\n",
      "level 1 merge detection- goes  up 10\n",
      "level 1 merge detection- goes  up 11\n",
      "level 1 merge detection- goes  up 12\n",
      "level 1 merge detection- goes  up 13\n",
      "level 2 merge detection- goes  down v1 14\n",
      "No pattern found in level 3 doown check v2 14\n",
      "PP level 4 - max columns  15\n",
      "True letter round\n",
      "2 pixels  left move on\n",
      "...................\n",
      "object initial coordinates 16 25\n",
      "we are inside m search 16\n",
      "m  found\n",
      "we are inside M,N search /max5 24\n",
      "we are inside M,N search /max6 24\n",
      "we are inside M,N search /max7 24\n",
      "we are inside M,N search /max8 24\n",
      "True letter round\n",
      "2 pixels  left move on\n",
      "...................\n",
      "pixels line [0, 16]\n",
      "[letter_pixels] [[[0, 16, 0, 1], [0, 16, 2, 4], [0, 16, 8, 16], [0, 16, 16, 24]]]\n",
      "key is 12\n",
      "lines recogized for  image: ex_001.png\n"
     ]
    }
   ],
   "source": [
    "dictionary=[]\n",
    "for p in photos:\n",
    "    print(p)\n",
    "\n",
    "    #create a path for each image to store the results of text objects, text lines and the word file with the classification output.\n",
    "    path_objs=os.path.join(data_output_folder, 'recognition', 'objects\\\\'+p+'\\\\')\n",
    "    print('path_objs', path_objs, '\\\\')\n",
    "    #path_objs_original= '.\\\\app_output\\\\recognition\\\\objects\\\\'+p+'\\\\' #path to text objects\n",
    "    #print('path_objs_original', path_objs_original)\n",
    "    create_path(path_objs)\n",
    "\n",
    "    path_lines=os.path.join(data_output_folder, 'recognition', 'lines\\\\'+p+'\\\\') #path to objext text lines\n",
    "    #path_lines='.\\\\app_output\\\\recognition\\\\lines\\\\'+p+'\\\\' #path to objext text lines\n",
    "    create_path(path_lines)\n",
    "\n",
    "    path_words=os.path.join(data_output_folder, 'recognition', 'words\\\\'+p+'\\\\') \n",
    "    #path_words='.\\\\app_output\\\\recognition\\\\words\\\\'+p+'\\\\'\n",
    "    create_path(path_words)\n",
    "\n",
    "    path_letters=os.path.join(data_output_folder, 'recognition', 'letters\\\\'+p+'\\\\') \n",
    "    #path_letters='.\\\\app_output\\\\recognition\\\\letters\\\\'+p+'\\\\'\n",
    "    create_path(path_letters)\n",
    "\n",
    "    path_quant=os.path.join(data_output_folder, 'recognition', 'quantized\\\\'+p+'\\\\') \n",
    "    #path_quant='.\\\\app_output\\\\recognition\\\\quantized\\\\'+p+'\\\\'\n",
    "    create_path(path_quant)\n",
    "        \n",
    "        \n",
    "    \n",
    "    img=cv2.imread(os.path.join(data_input_folder, p))\n",
    "    #img=cv2.imread(os.path.join()'.\\\\data\\\\'+p)\n",
    "\n",
    "    thresh,gray=preprocess_orig_img(img)\n",
    "    horizontal_p1=mask_morph(get_horizodal_lines(thresh.copy(),25),thresh.copy())\n",
    "    vertical=mask_morph(get_vertical_lines(thresh.copy(),50),horizontal_p1.copy()) #20\n",
    "    image_wide=wide_white_contours(vertical.copy(),int(img.shape[0]*expot(vertical.copy())),int(img.shape[1] * expot(vertical.copy())))\n",
    "    noise_removed=remove_noise(image_wide.copy())  \n",
    "    masked_img_n, masked_img_weighted_big_n,masked_img_nf, masked_img_weighted_big_nf,masked_img_nfs, masked_img_weighted_big_nfs,        filter1_nf=extract_contoured_image_1(img.copy(), noise_removed.copy(),0,0,0.2,0.8)\n",
    "    masked_imgf2,masked_img_weighted_bigf2,filter1_f2=extract_contoured_image_2(img.copy(), filter1_nf.copy(),0,0,0.2,0.8)\n",
    "    write_images_pre(masked_imgf2,masked_img_weighted_bigf2,p)\n",
    "\n",
    "    lines,temp_object= extract_object(img.copy(),filter1_f2,p,path_objs)\n",
    "\n",
    "    if not 'base_images' in temp_object:\n",
    "        temp_object['base_images'] = []\n",
    "    \n",
    "    temp_object['base_images'].append(img)\n",
    "\n",
    "    if not 'image_name' in temp_object:\n",
    "        temp_object['image_name'] = []\n",
    "    \n",
    "    temp_object['image_name'].append(p)\n",
    "\n",
    "            \n",
    "    ##Line detection\n",
    "    ###################################################################################################################\n",
    "    idl=0 #id for line per image\n",
    "    idw=0 #id for word per image\n",
    "    idq=0 #quantized image\n",
    "    idt=0 #text letter\n",
    "    mydoc_tesseract = docx.Document()\n",
    "    for key in range (0,len(temp_object['line_images'])):\n",
    "        print('line image', key)\n",
    "        #get an object image\n",
    "        img_line=temp_object['line_images'][key]\n",
    "        \n",
    "        #preprocess it\n",
    "        try:\n",
    "            img_score,img_res=line_preprocessing(img_line, 31,29,19,17,30,0,0,4,3,'two')  \n",
    "            print('Base Image')\n",
    "        except:\n",
    "            img_score,img_res=line_preprocessing_advanced(img_line) \n",
    "            print('Base Image v2 / can be deleted')\n",
    "            \n",
    "        #get all the lines per object and line pixels write them on a path\n",
    "        line_images,pixels,idl=line_detection(img_score,img_res,path_lines,idl)\n",
    "        print('line detection pixels', pixels)\n",
    "    \n",
    "        #1 text output per maximum hierarchy\n",
    "        text=[]\n",
    "        \n",
    "        #recognition\n",
    "        for line in range (0,len(line_images)):\n",
    "            #get all the words for complicated objects that lines cant be identified\n",
    "            if check_for_complicated_lines(0.2,0.85,10,line_preprocessing(line_images[line],13,9,0,0,30,2,0,0,0,'one'))==True:\n",
    "                words_images,words_pixels,idw=word_detection(idw,path_words,line_preprocessing(line_images[line],13,9,0,0,30,2,0,3,3,'one'))\n",
    "                           \n",
    "                for w in range(0, len(words_images)):\n",
    "                    idq+=1\n",
    "                    text_tesseract=tesseract_recognition(words_images[w],path_to_my_tesseract,False,20)\n",
    "                    mydoc_tesseract.add_paragraph(text_tesseract)\n",
    "                    text.append(text_tesseract)\n",
    "                    \n",
    "                    #start letter recognition\n",
    "                    colors_count_sorted,color_arr,backround_id =get_color_ids(words_images[w])\n",
    "                    image_color_decr=colors_decrease_minkowski_v2(color_arr,backround_id,words_images[w],1.5)\n",
    "                    quant1=quantizate_colors(image_color_decr,14,2)\n",
    "                    quant2=quantizate_colors(quant1,2,30)\n",
    "                    colors_count_sorted,color_array,backround_id=get_color_ids(quant2)\n",
    "                    image_underscore=check_for_underscore(quant2,color_array)\n",
    "                    image_hough= horizodal_lines_remove_Hough(image_underscore,backround_id,0.15,0.05)\n",
    "                    cv2.imwrite(path_quant+str(idq) + '.png', quant2)\n",
    "                    colordictioary, color_array,backround_id=get_color_ids(image_hough)\n",
    "                    colors_first_color_index,colors_last_color_index,colors_count_by_column_all_colors=count_occur_color_by_row_and_column(image_hough,color_array)\n",
    "                    try:\n",
    "                        y_dif=abs(colors_first_color_index[colors_first_color_index>0].min()-colors_last_color_index[colors_last_color_index>0].max())\n",
    "                        #returns letter pixels by line word\n",
    "                        idt,letter_pixels,letter_images=cut_to_characters(words_images[w],image_hough,colors_count_by_column_all_colors,colors_first_color_index,colors_last_color_index,idt,path_letters)\n",
    "                    except:\n",
    "                        #support filtering of symbols\n",
    "                        letter_pixels=[]\n",
    "                        print('icon')\n",
    "                    #aggregate the pixels with lines     \n",
    "                    pixels[line]=pixels[line]+[words_pixels[w]+[letter_pixels]]\n",
    "            else:\n",
    "                text_tesseract=tesseract_recognition(line_images[line],path_to_my_tesseract,False,20)\n",
    "                mydoc_tesseract.add_paragraph(text_tesseract)\n",
    "                text.append(text_tesseract) \n",
    "                #start letter recognition\n",
    "                \n",
    "                colors_count_sorted,color_arr,backround_id =get_color_ids(line_images[line])\n",
    "                image_color_decr=colors_decrease_minkowski_v2(color_arr,backround_id,line_images[line],1.5)\n",
    "                quant1=quantizate_colors(image_color_decr,14,2)\n",
    "                quant2=quantizate_colors(quant1,2,30)\n",
    "                colors_count_sorted,color_array,backround_id=get_color_ids(quant2)\n",
    "                image_underscore=check_for_underscore(quant2,color_array)\n",
    "                image_hough= horizodal_lines_remove_Hough(image_underscore,backround_id,0.15,0.05)\n",
    "                cv2.imwrite(path_quant+str(idq) + '.png', quant2)\n",
    "                colordictioary, color_array,backround_id=get_color_ids(image_hough)\n",
    "\n",
    "            \n",
    "                colors_first_color_index,colors_last_color_index,colors_count_by_column_all_colors=count_occur_color_by_row_and_column(image_hough,color_array)\n",
    "                try:\n",
    "                    y_dif=abs(colors_first_color_index[colors_first_color_index>0].min()-colors_last_color_index[colors_last_color_index>0].max())\n",
    "                    #returns letter pixels by line\n",
    "                    idt,letter_pixels,letter_images=cut_to_characters(line_images[line],image_hough,colors_count_by_column_all_colors,colors_first_color_index,colors_last_color_index,idt,path_letters)\n",
    "                except Exception as e:\n",
    "                    #helps to reduce symbols\n",
    "                    letter_pixels=[]\n",
    "                    print(str(e))\n",
    "                    \n",
    "                print('pixels line', pixels[line])\n",
    "                print('[letter_pixels]', [letter_pixels])\n",
    "                pixels[line]=pixels[line]+[letter_pixels]\n",
    "\n",
    "        temp_object['ocr_text'][key]=text\n",
    "        print('key is', key)\n",
    "\n",
    "        temp_object['sub_coordinates'][key]=pixels\n",
    "\n",
    "    #mydoc_tesseract.save(path_lines+\"OCR_output_teserract.docx\")\n",
    "    mydoc_tesseract.save(os.path.join(path_lines, 'OCR_output_teserract.docx'))\n",
    "    print('lines recogized for  image:',p)\n",
    "            \n",
    "#save the object\n",
    "np.save(os.path.join(data_output_folder, 'object_output.npy'), temp_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrutura de dados\n",
    "result = [{'objBbox': [], 'text': '', 'chars': [{'charBbox': [], 'char': ''}] }]\n",
    "\n",
    "for imgIdx in range(0, len(temp_object['base_images'])):\n",
    "    print('imgIdx', imgIdx)\n",
    "    img = temp_object['base_images'][imgIdx]\n",
    "    annot_img = img.copy()\n",
    "    image_name = temp_object['image_name'][imgIdx]\n",
    "    image_annotation_folder = os.path.join(data_output_folder, 'images_annotated', image_name)\n",
    "    create_path(image_annotation_folder)\n",
    "\n",
    "    for objectBboxIdx in range (0, len(temp_object['coordinates_line'])):\n",
    "        objectBbox = temp_object['coordinates_line'][objectBboxIdx]  #coordinates in the form of y0, y1, x0, x1\n",
    "        #print('objectBbox', objectBbox)\n",
    "\n",
    "        snippet = img[objectBbox[0]: objectBbox[1], objectBbox[2]: objectBbox[3]]\n",
    "        cv2.imwrite(os.path.join(image_annotation_folder, \"snippet_\" + str(objectBboxIdx) + \".png\"), snippet)\n",
    "\n",
    "        for coordIdx in range (0,len(temp_object['sub_coordinates'][0][0][2:][0])): #coordinates in the form of y0, y1, x0, x1\n",
    "            charBbox = temp_object['sub_coordinates'][objectBboxIdx][0][2:][0][coordIdx]\n",
    "            #print('charBbox', charBbox)\n",
    "            y0 = charBbox[0]\n",
    "            y1 = charBbox[1]\n",
    "            x0 = charBbox[2]\n",
    "            x1 = charBbox[3]\n",
    "\n",
    "            relBbox = [y0, y1, x0, x1]\n",
    "            #print('relBbox',relBbox)\n",
    "\n",
    "            snippet_char = snippet[y0: y1, x0: x1]\n",
    "\n",
    "            snippet_char_path = \"snippet_\" + str(objectBboxIdx) + \"char_\" + str(coordIdx) + \".png\"\n",
    "            cv2.imwrite(os.path.join(image_annotation_folder, \"snippet_\" + str(objectBboxIdx) + \"_char_\" + str(coordIdx) + \".png\"), snippet_char)\n",
    "            \n",
    "            y0 = objectBbox[0] + charBbox[0]\n",
    "            y1 = objectBbox[0] + charBbox[1]\n",
    "            x0 = objectBbox[2] + charBbox[2]\n",
    "            x1 = objectBbox[2] + charBbox[3]\n",
    "            absBbox = [y0, y1, x0, x1]\n",
    "            #print('absBbox', absBbox)\n",
    "            \n",
    "            cv2.rectangle(annot_img, (x0, y0), (x1, y1), (255, 0, 0), 1)\n",
    "\n",
    "    image_annotated_path = os.path.join(image_annotation_folder, 'annotation.png')\n",
    "    print('image_annotated_path', image_annotated_path)\n",
    "    cv2.imwrite(image_annotated_path, annot_img)\n",
    "\n",
    "    \n",
    "            # a seguir preciso de invocar o char recognizer p/ cada caracter\n",
    "           # recognizer = os.path.join()\n",
    "        \n",
    "        #aqui concateno todo os chars reconhecidos na propriedade 'text'\n",
    "        \n",
    "        '''\n",
    "        p/ terça 02/11\n",
    "\n",
    "        necessário pôr o recognition a reconhecer snippets passados como image array e meter loops em funcoes\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://iq-inc.com/importerror-attempted-relative-import/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recogntition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('object_output.npy', temp_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "read_dictionary = np.load('object_output.npy',allow_pickle='TRUE').item()\n",
    "print(read_dictionary)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
