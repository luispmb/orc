{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticai_exec\n",
    "#print('gonna install python docx')\n",
    "#!pip install python-docx\n",
    "#import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING LOCALLY\n",
      "instantiateS3\n",
      "s3 instantiated\n",
      "myDir c:\\Users\\JosePombo\\Desktop\\repos\\ocr\\controllers\n",
      "parentDir c:\\Users\\JosePombo\\Desktop\\repos\\ocr\n",
      "A\n",
      "Number of files downloaded: 0\n",
      "Total size: 0.000 MB\n",
      "Elapsed time: 2s\n",
      "files ['.dockerignore', '.env', '.git', '.gitignore', '.ipynb_checkpoints', '02-Classifiers', '03-Object Detection-GAN', '04-Recognition', '13-Object Detection-Tesseract', '5_orchestrator - original.ipynb', '5_orchestrator_predict.ipynb', 'A4_generate_GAN_images_array.ipynb', 'A4_generate_GAN_images_array.py', 'api', 'code_dictionary.docx', 'config', 'controllers', 'custom_requirements.txt', 'Dockerfile', 'Dockerfile_', 'main.py', 'main2.py', 'models_tmp', 'ocr - pds.txt', 'ocr-image', 'OCR_presentation.pptx', 'README.md', 'requirements copy.txt', 'requirements.txt', 'test', 'teste.ipynb', 'Use AutoAI and AI lifecycle to predict credit risk.ipynb', 'utils', '_A4_generate_GAN_images_array.py', '__pycache__']\n",
      "platformDirOCR c:\\Users\\JosePombo\\Desktop\\repos\\ocr\\controllers\n",
      " os.getcwd() c:\\Users\\JosePombo\\Desktop\\repos\\ocr\n",
      " os.getcwd() c:\\Users\\JosePombo\\Desktop\\repos\\ocr\\controllers\n",
      "files ['.ipynb_checkpoints', '.pytest_cache', 'char_classification.py', 'char_recognition.ipynb', 'char_recognition.py', 'char_recognition_original.ipynb', 'cut_to_characters.py', 'functions_char_detection.py', 'functions_char_preparation.py', 'functions_line_detection.py', 'functions_object_detection.py', 'functions_score.py', 'functions_word_detection.py', 'line_breakdown.py', 'line_detection.py', 'object_detection.ipynb', 'object_detection.py', 'object_detection_original.ipynb', 'ocr.ipynb', 'ocr.py', 'recogntition.py', '__pycache__']\n",
      "checkpoint 1\n",
      "checkpoint 3\n"
     ]
    }
   ],
   "source": [
    "#elasticai_exec\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "#where_am_i = os.system('hostname')\n",
    "#hostname=os.popen('hostname').read()\n",
    "#print('hostname', hostname)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(\"\")\n",
    "\n",
    "runApplication = True\n",
    "\n",
    "if \"RUNNING_LOCALLY\" in os.environ.keys() and os.environ[\"RUNNING_LOCALLY\"] == \"True\":\n",
    "    print('RUNNING LOCALLY')\n",
    "    #sys.path.insert(0, '..')\n",
    "    #sys.path.append(\"\")\n",
    "    from utils.util_s3 import instantiateS3\n",
    "    s3 = instantiateS3()\n",
    "\n",
    "myDir = os.getcwd()\n",
    "print('myDir', myDir)\n",
    "\n",
    "parentDir = os.path.dirname(os.getcwd())\n",
    "print('parentDir', parentDir)\n",
    "\n",
    "os.chdir(parentDir) #mudar wd pra root\n",
    "#sys.path.append(\"\")\n",
    "\n",
    "\n",
    "#s3DirOCR = os.path.join(parentDir, 'ocr')\n",
    "#print('s3DirOCR', s3DirOCR)\n",
    "\n",
    "if \"RUNNING_LOCALLY\" in os.environ.keys() and os.environ[\"RUNNING_LOCALLY\"] == \"True\":\n",
    "    print('A')\n",
    "    #sys.path.append(\"\")\n",
    "    s3DirOCR = os.path.join(parentDir, 'ocr')\n",
    "    platformDirOCR = os.path.join(os.getcwd(), 'controllers')\n",
    " \n",
    "else:\n",
    "    print('B')\n",
    "    #sys.path.append(\"\")\n",
    "    s3DirOCR = parentDir\n",
    "    platformDirOCR = os.path.join(os.getcwd(), 'ocr')\n",
    "    \n",
    "\n",
    "#s3({\"path\": s3DirOCR, \"localPath\": '/'}, \"readFolder\")\n",
    "s3({\"path\": parentDir, \"localPath\": '/'}, \"readFolder\")\n",
    "\n",
    "print('files', os.listdir())\n",
    "\n",
    "\n",
    "print('platformDirOCR', platformDirOCR)\n",
    "\n",
    "print(' os.getcwd()',  os.getcwd())\n",
    "\n",
    "os.chdir(platformDirOCR)\n",
    "print(' os.getcwd()',  os.getcwd())\n",
    "print('files', os.listdir())\n",
    "#print('files', os.listdir())\n",
    "\n",
    "\n",
    "#from object_detection import detect\n",
    "print('checkpoint 1')\n",
    "from utils.util_callFunction import callFunction\n",
    "#print('checkpoint 2')\n",
    "#import object_detection\n",
    "#object_detection= __import__('object_detection')\n",
    "#from char_recognition import recognize\n",
    "print('checkpoint 3')\n",
    "\n",
    "\n",
    "parent_directory = os.path.abspath('')\n",
    "root = os.path.abspath(os.path.join(parent_directory, os.pardir))\n",
    "data_output_folder = os.path.join(root, 'test', 'data', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticai_exec\n",
    "import datetime;\n",
    "start = datetime.datetime.now()\n",
    "print(\"current time:-\", start)\n",
    "\n",
    "\n",
    "objectsDetected = callFunction('object_detection.py', ['ex_001.png'], False, False)\n",
    "print('objectsDetected', objectsDetected)\n",
    "\n",
    "current = datetime.datetime.now()\n",
    "print('diff time', current - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('objectsDetected', objectsDetected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticai_exec\n",
    "#recognize()\n",
    "\n",
    "chars_recognized = {\"chars\": []}\n",
    "\n",
    "for imgIndex, imgResult in enumerate(objectsDetected['result']):\n",
    "    print('imgIndex', imgIndex)\n",
    "    #print('imgResult')\n",
    "    for objectIndex, objectDetected in enumerate(imgResult['objBboxes']):\n",
    "        #print(objectDetected)\n",
    "        print('objectIndex', objectIndex)\n",
    "        object_string = ''\n",
    "        for charIndex, charDetected in enumerate(objectDetected['chars']):\n",
    "            print('charIndex', charIndex)\n",
    "            #print('charDetected', charDetected)\n",
    "            #char_string = recognize(charDetected['snippet'])\n",
    "            chars_recognized['chars'].append({})\n",
    "            chars_recognized['chars'][charIndex]['index'] = charIndex\n",
    "            #chars_recognized['chars'][charIndex]['char'] = callFunction('char_recognition.py', charDetected['snippet'], True)\n",
    "            callFunction('char_recognition', charDetected['snippet'], True, True)\n",
    "            #objectsDetected['result'][imgIndex]['objBboxes'][objectIndex]['chars'][charIndex]['text'] = chars_recognized['chars'][charIndex]['char']\n",
    "            \n",
    "            \n",
    "            #object_string += chars_recognized['chars'][charIndex]['char']\n",
    "            \n",
    "            del objectsDetected['result'][imgIndex]['objBboxes'][objectIndex]['chars'][charIndex]['snippet']\n",
    "\n",
    "        print('chars_recognized', chars_recognized)\n",
    "        #object_string +=  ''.join([charDict['char'] for charDict in chars_recognized['chars'] if charDict.__contains__('char')])\n",
    "\n",
    "        objectsDetected['result'][imgIndex]['objBboxes'][objectIndex]['text'] = object_string\n",
    "        del objectsDetected['result'][imgIndex]['objBboxes'][objectIndex]['snippet']\n",
    "    del objectsDetected['result'][imgIndex]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticai_exec\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticai_exec\n",
    "#json_dump = json.dumps(objectsDetected, cls=NumpyEncoder)\n",
    "outputLabelname = 'result.json'\n",
    "\n",
    "with open(os.path.join(data_output_folder, outputLabelname), 'w') as fp:\n",
    "    json.dump(objectsDetected, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFilename = os.path.join('OCR', 'Final', 'test', 'data', 'output', outputLabelname)\n",
    "outputFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3({\"path\": outputFilename, \"data\": objectsDetected, \"isFile\": False }, \"write\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
