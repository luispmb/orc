{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "import os\n",
    "parent_directory = os.path.abspath('')\n",
    "root = os.path.abspath(os.path.join(parent_directory, os.pardir))\n",
    "data_folder = '01-Data'\n",
    "classifiers_folder = '02-Classifiers'\n",
    "gan_char_models_folder = 'models_char_gan'\n",
    "model_digits_letters_name = 'class_char_model_{}.h5'\n",
    "mixed_models_folder = 'models_mixed'\n",
    "model_symbols_letters_name = 'model_0symbol_1letter.h5'\n",
    "model_0_oO_name = 'model_0_oO.h5'\n",
    "\n",
    "characters_folder = 'characters'\n",
    "test_images_folder = os.path.join(parent_directory, characters_folder)\n",
    "character_to_test = '{}.png'\n",
    "\n",
    "data_input_folder = os.path.join(root, 'test', 'data', 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_score import *\n",
    "from functions_char_preparation import *\n",
    "from char_classification import classification, image_char_prepr\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import pandas as pd\n",
    "import keras.backend as K #clear RAM\n",
    "import docx\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\JosePombo\\\\Desktop\\\\repos\\\\ocr\\\\controllers'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buidDictionary():\n",
    "\n",
    "    characters_all = list(string.printable)[:-6] #+['รง']# <\n",
    "    j=-1\n",
    "    dict_target=[]\n",
    "    for char in characters_all:\n",
    "        j=j+1\n",
    "        dict_target.append([char,ord(char),j])\n",
    "    dictionar=pd.DataFrame(dict_target).rename(columns={0:'Actual_char',1:'Actual_num',2:'Actual_id'})\n",
    "\n",
    "    dictionar_symbols=dictionar[62:94]\n",
    "    dictionar_letters=dictionar[0:62]\n",
    "\n",
    "    #threshold for _,-\n",
    "    from pandas import DataFrame\n",
    "    pd_ = DataFrame(np.arange(0,32,1))\n",
    "    Q1_ = pd_.quantile(0.25)\n",
    "    Q3_ = pd_.quantile(0.75)\n",
    "    IQR_ = Q3_ - Q1_\n",
    "\n",
    "    return characters_all, dictionar, dictionar_letters, dictionar_symbols, Q1_, Q3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Models():\n",
    "    def addModel(self, modelsPath, modelOgirinalName, modelName):\n",
    "        #char_models_filename = modelsPath.format(ord(char))\n",
    "        char_models_filename = os.path.join(modelsPath, modelOgirinalName)\n",
    "        print('char_models_filename', char_models_filename)\n",
    "\n",
    "        if not hasattr(self, modelName):\n",
    "            ml_model=tf.keras.models.load_model(char_models_filename)\n",
    "\n",
    "            if modelName:\n",
    "                setattr(self, modelName, ml_model)\n",
    "            else:\n",
    "                setattr(self, modelOgirinalName, ml_model)\n",
    "        else:\n",
    "            print('model ', modelName, ' in memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModels(characters_all):\n",
    "    \n",
    "    if not 'charModels' in globals():\n",
    "        print('charModels not in locals neither in globals')\n",
    "        global charModels\n",
    "        charModels = ML_Models()\n",
    "        print('charModels', charModels)\n",
    "\n",
    "        gan_char_models_path = os.path.join(root, classifiers_folder, gan_char_models_folder)\n",
    "        for char in characters_all[0:62]:\n",
    "            print(char)\n",
    "            charModels.addModel(gan_char_models_path, model_digits_letters_name.format(ord(char)), f'model_letters{ord(char)}')\n",
    "            #K.clear_session()\n",
    "\n",
    "\n",
    "        mixed_models_path = os.path.join(root, classifiers_folder, mixed_models_folder)\n",
    "        for char in characters_all[62:94]:\n",
    "            print(char)\n",
    "            charModels.addModel(mixed_models_path, model_symbols_letters_name, f'model_symbols{ord(char)}')\n",
    "            #K.clear_session()\n",
    "            \n",
    "        charModels.addModel(mixed_models_path, model_symbols_letters_name, 'model_symbols_letters')      \n",
    "        charModels.addModel(mixed_models_path, model_0_oO_name, 'model_0_oO')\n",
    "\n",
    "    else:\n",
    "        print('charModels instantiated')       \n",
    "\n",
    "    return charModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_img_preprocessing(img):\n",
    "    #print('char_img_preprocessing', img)\n",
    "\n",
    "    #img = cv2.imread(char_image)\n",
    "    #print('img', img)\n",
    "    #img = cv2.imread('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\04-Recognition\\\\characters\\\\2.png')\n",
    "\n",
    "    sorted_ctrs = char_preprocessing_step_1(img)\n",
    "    #print('sorted_ctrs', sorted_ctrs)\n",
    "    new_sorted_ctrs = char_preprocessing_step_2(sorted_ctrs,img)\n",
    "    #print('new_sorted_ctrs', new_sorted_ctrs)\n",
    "    temp_max_yh,temp_min_y = char_preprocessing_step_3(new_sorted_ctrs) #normalize height\n",
    "    #print('temp_max_yh', temp_max_yh)\n",
    "    #print('temp_min_y', temp_min_y)\n",
    "    \n",
    "    char_image,char_image_nh = char_preprocessing_step_4(img,new_sorted_ctrs,temp_max_yh,temp_min_y)\n",
    "    \n",
    "    return char_image, char_image_nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_recognition(charModels, new_img, new_img_normheight, dictionar, dictionar_letters, dictionar_symbols, Q1_,Q3_): #recognize char     \n",
    "    import cv2 \n",
    "    import  numpy as np\n",
    "    \n",
    "    resized=image_char_prepr(new_img,2,20,0)\n",
    "    resized_normheight=image_char_prepr(new_img_normheight,2,20,0)\n",
    "\n",
    "    new_image_density=resized.sum()\n",
    "\n",
    "    x_test_right = np.expand_dims(resized, axis=-1)\n",
    "    x_test = np.expand_dims(x_test_right, axis=0)\n",
    "    forecast,dictionartemp = classification(charModels, resized, resized_normheight, x_test, Q1_, Q3_, dictionar, dictionar_letters, dictionar_symbols)\n",
    "    text_char =str(forecast)\n",
    "    return text_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "caracteres com problemas: 132, 140, 147, 186, 194, 233, 241, 280, 288\n",
    "'''\n",
    "unhandledChars = [140, 147, 186, 194, 233, 241, 280, 288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(char_image):\n",
    "    if len(char_image) == 0:\n",
    "        data_input_folder = os.path.join(root, 'test', 'data', 'input')\n",
    "        data_input_char_folder = os.path.join(data_input_folder, 'char_recognition')\n",
    "        char_images_names = [f for f in listdir(data_input_char_folder) if isfile(join(data_input_char_folder, f))]\n",
    "        print('char_images_names', char_images_names)\n",
    "        char_image_name = char_images_names[0]\n",
    "        char_image=cv2.imread(os.path.join(data_input_char_folder, char_image_name))\n",
    "\n",
    "    characters_all, dictionar, dictionar_letters, dictionar_symbols, Q1_, Q3_ = buidDictionary()\n",
    "    \n",
    "    charModels = loadModels(characters_all)\n",
    "\n",
    "    _char_image, char_image_nh = char_img_preprocessing(char_image)\n",
    "\n",
    "    text_char = char_recognition(charModels, _char_image[0], char_image_nh[0], dictionar, dictionar_letters, dictionar_symbols, Q1_, Q3_)\n",
    "    print('text_char', text_char)\n",
    "\n",
    "    return text_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_images_names ['1.png', '10.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n",
      "charModels instantiated\n",
      "forecast_symbol_letter 1\n",
      "forecast D\n",
      "Forecast_letters:  D\n",
      "...........................................................\n",
      "text_char D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recognize([])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
