{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPENDENCIES\n",
    "#######################################################################################################################\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from functions_object_detection import create_path, preprocess_orig_img, mask_morph, get_horizodal_lines, get_vertical_lines, wide_white_contours, remove_noise, extract_contoured_image_2, extract_contoured_image_1, expot, write_images_pre, extract_object\n",
    "#from functions_line_detection import *\n",
    "from config.tesseract import path_to_my_tesseract\n",
    "#from functions_word_detection import check_for_complicated_lines, worqd_detection\n",
    "#from functions_char_detection import *\n",
    "#from cut_to_characters import *\n",
    "from utils.util_miscellaneous import changeDirectory\n",
    "from line_detection import line_detection\n",
    "\n",
    "#dont require pip\n",
    "import os\n",
    "import shutil\n",
    "import string\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#require pip\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "######################################################################################################################################\n",
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "#pytesseract.pytesseract.tesseract_cmd = path_to_my_tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = os.environ['path_to_my_tesseract']\n",
    "#custom_config = r'--oem 3 --psm 6'\n",
    "custom_config = r'-l por+eng --psm 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "parent_directory = os.path.abspath('')\n",
    "root = os.path.abspath(os.path.join(parent_directory, os.pardir))\n",
    "\n",
    "data_input_folder = os.path.join(root, 'test', 'data', 'input')\n",
    "data_output_folder = os.path.join(root, 'test', 'data', 'output')\n",
    "\n",
    "\n",
    "#clean and create paths to save images after preprocessing\n",
    "create_path(os.path.join(data_output_folder, 'filtered', 'output_all_br')) #source image preprocessing output with blured backround to compare\n",
    "create_path(os.path.join(data_output_folder, 'filtered', 'output_all')) #source image preprocessing output ready to exctract objects and lines\n",
    "create_path(os.path.join(data_output_folder, 'recognition')) # extracted objects, lines, and classification results\n",
    "\n",
    "\n",
    "#read all the source images for recognition\n",
    "#sourcepath='.\\\\data\\\\\\\\'\n",
    "sourcepath=data_input_folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrutura de dados\n",
    "def convertToFinalStructure(temp_object):\n",
    "    result = [{'objBbox': [], 'text': '', 'chars': [{'charBbox': [], 'char': ''}] }]\n",
    "\n",
    "    for imgIdx in range(0, len(temp_object['base_images'])):\n",
    "        print('imgIdx', imgIdx)\n",
    "        img = temp_object['base_images'][imgIdx]\n",
    "        annot_img = img.copy()\n",
    "        image_name = temp_object['image_name'][imgIdx]\n",
    "        image_annotation_folder = os.path.join(data_output_folder, 'images_annotated', image_name)\n",
    "        create_path(image_annotation_folder)\n",
    "\n",
    "        for objectBboxIdx in range (0, len(temp_object['coordinates_line'])):\n",
    "            objectBbox = temp_object['coordinates_line'][objectBboxIdx]  #coordinates in the form of y0, y1, x0, x1\n",
    "            #print('objectBbox', objectBbox)\n",
    "\n",
    "            snippet = img[objectBbox[0]: objectBbox[1], objectBbox[2]: objectBbox[3]]\n",
    "            cv2.imwrite(os.path.join(image_annotation_folder, \"snippet_\" + str(objectBboxIdx) + \".png\"), snippet)\n",
    "\n",
    "            for coordIdx in range (0,len(temp_object['sub_coordinates'][0][2:][0])): #coordinates in the form of y0, y1, x0, x1\n",
    "                charBbox = temp_object['sub_coordinates'][objectBboxIdx][2:][0][coordIdx]\n",
    "                #print('charBbox', charBbox)\n",
    "                y0 = charBbox[0]\n",
    "                y1 = charBbox[1]\n",
    "                x0 = charBbox[2]\n",
    "                x1 = charBbox[3]\n",
    "\n",
    "                relBbox = [y0, y1, x0, x1]\n",
    "                #print('relBbox',relBbox)\n",
    "\n",
    "                snippet_char = snippet[y0: y1, x0: x1]\n",
    "\n",
    "                snippet_char_path = \"snippet_\" + str(objectBboxIdx) + \"char_\" + str(coordIdx) + \".png\"\n",
    "                cv2.imwrite(os.path.join(image_annotation_folder, \"snippet_\" + str(objectBboxIdx) + \"_char_\" + str(coordIdx) + \".png\"), snippet_char)\n",
    "                \n",
    "                y0 = objectBbox[0] + charBbox[0]\n",
    "                y1 = objectBbox[0] + charBbox[1]\n",
    "                x0 = objectBbox[2] + charBbox[2]\n",
    "                x1 = objectBbox[2] + charBbox[3]\n",
    "                absBbox = [y0, y1, x0, x1]\n",
    "                #print('absBbox', absBbox)\n",
    "                \n",
    "                cv2.rectangle(annot_img, (x0, y0), (x1, y1), (255, 0, 0), 1)\n",
    "\n",
    "        image_annotated_path = os.path.join(image_annotation_folder, 'annotation.png')\n",
    "        print('image_annotated_path', image_annotated_path)\n",
    "        cv2.imwrite(image_annotated_path, annot_img)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(imageName):\n",
    "\n",
    "    dictionary=[]\n",
    "    #create a path for each image to store the results of text objects, text lines and the word file with the classification output.\n",
    "    path_objs=os.path.join(data_output_folder, 'recognition', 'objects\\\\'+imageName+'\\\\')\n",
    "    create_path(path_objs)\n",
    "    path_lines=os.path.join(data_output_folder, 'recognition', 'lines\\\\'+imageName+'\\\\') #path to objext text lines\n",
    "    create_path(path_lines)\n",
    "    path_words=os.path.join(data_output_folder, 'recognition', 'words\\\\'+imageName+'\\\\') \n",
    "    create_path(path_words)\n",
    "    path_letters=os.path.join(data_output_folder, 'recognition', 'letters\\\\'+imageName+'\\\\') \n",
    "    create_path(path_letters)\n",
    "    path_quant=os.path.join(data_output_folder, 'recognition', 'quantized\\\\'+imageName+'\\\\') \n",
    "    create_path(path_quant)\n",
    "        \n",
    "    img=cv2.imread(os.path.join(data_input_folder, imageName))\n",
    "\n",
    "    thresh,gray=preprocess_orig_img(img)\n",
    "    horizontal_p1=mask_morph(get_horizodal_lines(thresh.copy(),25),thresh.copy())\n",
    "    vertical=mask_morph(get_vertical_lines(thresh.copy(),50),horizontal_p1.copy()) #20\n",
    "    image_wide=wide_white_contours(vertical.copy(),int(img.shape[0]*expot(vertical.copy())),int(img.shape[1] * expot(vertical.copy())))\n",
    "    noise_removed=remove_noise(image_wide.copy())  \n",
    "    masked_img_n, masked_img_weighted_big_n,masked_img_nf, masked_img_weighted_big_nf,masked_img_nfs, masked_img_weighted_big_nfs,filter1_nf=extract_contoured_image_1(img.copy(), noise_removed.copy(),0,0,0.2,0.8)\n",
    "    masked_imgf2,masked_img_weighted_bigf2,filter1_f2=extract_contoured_image_2(img.copy(), filter1_nf.copy(),0,0,0.2,0.8)\n",
    "    write_images_pre(masked_imgf2, masked_img_weighted_bigf2, imageName)\n",
    "\n",
    "    lines, temp_object = extract_object(img.copy(), filter1_f2, imageName, path_objs)\n",
    "\n",
    "    if not 'base_images' in temp_object:\n",
    "        temp_object['base_images'] = []\n",
    "    \n",
    "    temp_object['base_images'].append(img)\n",
    "\n",
    "    if not 'image_name' in temp_object:\n",
    "        temp_object['image_name'] = []\n",
    "    \n",
    "    temp_object['image_name'].append(imageName)\n",
    "\n",
    "            \n",
    "    ##Line detection\n",
    "    ###################################################################################################################\n",
    "    idl=0 #id for line per image\n",
    "    idw=0 #id for word per image\n",
    "    idq=0 #quantized image\n",
    "    idt=0 #text letter\n",
    "    mydoc_tesseract = docx.Document()\n",
    "    for key in range (0,len(temp_object['line_images'])):\n",
    "        print('line image', key)\n",
    "        \n",
    "        #get an object image\n",
    "        img_line=temp_object['line_images'][key]\n",
    "\n",
    "        pixels, text = line_detection(img_line, temp_object, path_lines, idl, key, mydoc_tesseract, path_quant, idw, idq, path_words, idt, path_letters)\n",
    "        \n",
    "        temp_object['ocr_text'][key]=text\n",
    "\n",
    "        print('pixels', pixels)\n",
    "\n",
    "        temp_object['sub_coordinates'][key]=pixels\n",
    "\n",
    "    #mydoc_tesseract.save(path_lines+\"OCR_output_teserract.docx\")\n",
    "    mydoc_tesseract.save(os.path.join(path_lines, 'OCR_output_teserract.docx'))\n",
    "    print('lines recogized for  image:', imageName)\n",
    "            \n",
    "    #save the object\n",
    "    # np.save(os.path.join(data_output_folder, 'object_output.npy'), temp_object)\n",
    "\n",
    "    temp_object = convertToFinalStructure(temp_object)\n",
    "    \n",
    "    return temp_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(imagesNames):\n",
    "    if len(imagesNames) == 0:\n",
    "        imagesNames = [f for f in listdir(sourcepath) if isfile(join(sourcepath, f))]\n",
    "\n",
    "    for imageName in imagesNames:\n",
    "        print('imageName', imageName)\n",
    "        temp_object = object_detection(imageName)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
