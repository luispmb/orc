{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "import os\n",
    "parent_directory = os.path.abspath('')\n",
    "root = os.path.abspath(os.path.join(parent_directory, os.pardir))\n",
    "data_folder = '01-Data'\n",
    "classifiers_folder = '02-Classifiers'\n",
    "gan_char_models_folder = 'models_char_gan'\n",
    "model_digits_letters_name = 'class_char_model_{}.h5'\n",
    "mixed_models_folder = 'models_mixed'\n",
    "model_symbols_letters_name = 'model_0symbol_1letter.h5'\n",
    "model_0_oO_name = 'model_0_oO.h5'\n",
    "\n",
    "characters_folder = 'characters'\n",
    "test_images_folder = os.path.join(parent_directory, characters_folder)\n",
    "character_to_test = '{}.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_score import *\n",
    "from functions_char_preparation import *\n",
    "from char_classification import classification\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import pandas as pd\n",
    "import keras.backend as K #clear RAM\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\JosePombo\\\\Desktop\\\\repos\\\\ocr\\\\04-Recognition'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModels():\n",
    "    characters_all = list(string.printable)[:-6] #+['รง']# <\n",
    "    j=-1\n",
    "    dict_target=[]\n",
    "    for char in characters_all:\n",
    "        j=j+1\n",
    "        dict_target.append([char,ord(char),j])\n",
    "    dictionar=pd.DataFrame(dict_target).rename(columns={0:'Actual_char',1:'Actual_num',2:'Actual_id'})\n",
    "\n",
    "    dictionar_symbols=dictionar[62:94]\n",
    "    dictionar_letters=dictionar[0:62]\n",
    "    #print('dictionar_symbols', dictionar_symbols)\n",
    "    # print('dictionar_letters', dictionar_letters)\n",
    "\n",
    "\n",
    "    gan_char_models_path = os.path.join(root, classifiers_folder, gan_char_models_folder, model_digits_letters_name)\n",
    "    #gan_char_models_path.replace('%s', ord(char))\n",
    "    for char in characters_all[0:62]:\n",
    "        print(char)\n",
    "\n",
    "        #model_temp=tf.keras.models.load_model('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\02-Classifiers\\\\models_char_gan\\\\32_\\\\class_char_model_%s.h5'%(ord(char)))\n",
    "        gan_char_models_filename = gan_char_models_path.format(ord(char))\n",
    "        print('gan_char_models_filename', gan_char_models_filename)\n",
    "        model_temp=tf.keras.models.load_model(gan_char_models_filename)\n",
    "        #creates variable name dynamically\n",
    "        exec(f'model_letters{ord(char)} = model_temp')\n",
    "        K.clear_session()\n",
    "\n",
    "    mixed_models_path = os.path.join(root, classifiers_folder, mixed_models_folder)\n",
    "    for char in characters_all[62:94]:\n",
    "        print(char)\n",
    "        \n",
    "        # model_temp=tf.keras.models.load_model('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\02-Classifiers\\\\\\models_char_gan\\\\32_\\\\class_char_model_%s.h5'%(ord(char)))\n",
    "        gan_char_models_filename = gan_char_models_path.format(ord(char))\n",
    "        print('gan_char_models_filename', gan_char_models_filename)\n",
    "        model_temp=tf.keras.models.load_model(gan_char_models_filename)\n",
    "        #creates variable name dynamically\n",
    "        exec(f'model_symbols{ord(char)} = model_temp')\n",
    "        K.clear_session()\n",
    "        \n",
    "    #model_symbols_letters=tf.keras.models.load_model('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\02-Classifiers\\\\\\models_mixed\\\\model_0symbol_1letter.h5')\n",
    "    model_symbols_letters_path = os.path.join(mixed_models_path, model_symbols_letters_name)  \n",
    "    model_symbols_letters=tf.keras.models.load_model(model_symbols_letters_path)         \n",
    "\n",
    "    #0 takes 0 ,oO takes 1\n",
    "    #model_0_oO =tf.keras.models.load_model('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\02-Classifiers\\\\\\models_mixed\\\\model_0_oO.h5') \n",
    "    model_0_oO_path = os.path.join(mixed_models_path, model_0_oO_name)\n",
    "    model_0_oO =tf.keras.models.load_model(model_0_oO_path)             \n",
    "\n",
    "    #threshold for _,-\n",
    "    from pandas import DataFrame\n",
    "    pd_=DataFrame(np.arange(0,32,1))\n",
    "    Q1_ = pd_.quantile(0.25)\n",
    "    Q3_ = pd_.quantile(0.75)\n",
    "    IQR_ = Q3_ - Q1_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_detection(new_img,new_img_normheight,dictionar,Q1_,Q3_): #detect char \n",
    "    \n",
    "    def image_char_prepr(img,dis_bound,blur,gray_thres):\n",
    "    \n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        import warnings\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        gray_char = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if gray_thres>0:\n",
    "        #https://stackoverflow.com/questions/49907382/how-to-remove-whitespace-from-an-image-in-opencv\n",
    "            gray = 255*(gray_char < gray_thres).astype(np.uint8) \n",
    "            coords = cv2.findNonZero(gray) # Find all non-zero points (text)\n",
    "            x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "            gray_char = gray_char[y:y+h, x:x+w] # Crop the image - note we do this on the original image\n",
    "\n",
    "        blur_char = cv2.bilateralFilter(gray_char, blur,blur, blur) #90, 90, 90\n",
    "        thresh_char = cv2.adaptiveThreshold(blur_char, 255, cv2.ADAPTIVE_THRESH_MEAN_C , \n",
    "                                           cv2.THRESH_BINARY_INV, 23, 19)\n",
    "        constant= cv2.copyMakeBorder(thresh_char.copy(),dis_bound,dis_bound,dis_bound,dis_bound,cv2.BORDER_CONSTANT)\n",
    "\n",
    "        resized=cv2.resize(constant,(32,32), interpolation = cv2.INTER_NEAREST)\n",
    "        return resized\n",
    "\n",
    "    \n",
    "    import cv2 \n",
    "    import  numpy as np\n",
    "    resized=image_char_prepr(new_img,2,20,0)\n",
    "    resized_normheight=image_char_prepr(new_img_normheight,2,20,0)\n",
    "\n",
    "    new_image_density=resized.sum()\n",
    "\n",
    "    x_test_right = np.expand_dims(resized, axis=-1)\n",
    "    x_test = np.expand_dims(x_test_right, axis=0)\n",
    "    forecast,dictionartemp = classification(resized,resized_normheight,dictionar,x_test,Q1_,Q3_)\n",
    "    text_char =str(forecast)\n",
    "    return text_char   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "caracteres com problemas\n",
    "132\n",
    "140\n",
    "147\n",
    "186\n",
    "194\n",
    "233\n",
    "241\n",
    "280\n",
    "288\n",
    "'''\n",
    "unhandledChars = [140, 147, 186, 194, 233, 241, 280, 288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_char 1\n",
      "test_char_image c:\\Users\\JosePombo\\Desktop\\repos\\ocr\\04-Recognition\\characters\\1.png\n",
      "new_sorted_ctrs [[1, 3, 11, 18, 21, 19]]\n",
      "temp_max_yh 21\n",
      "temp_min_y 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "char_detection() missing 1 required positional argument: 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JOSEPO~1\\AppData\\Local\\Temp/ipykernel_4092/446670415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print('char_image[0]', char_image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#print('char_image_nh[0]', char_image_nh)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtext_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchar_image_nh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ1_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ3_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#print('text_char', text_char)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: char_detection() missing 1 required positional argument: 'output'"
     ]
    }
   ],
   "source": [
    "test_char_list = range(1, 560)\n",
    "for test_char in test_char_list:\n",
    "    if not test_char  in unhandledChars:\n",
    "        test_char = str(test_char)\n",
    "        print('test_char', test_char)\n",
    "        test_char_image = os.path.join(test_images_folder, character_to_test.format(test_char))\n",
    "        print('test_char_image', test_char_image)\n",
    "        img = cv2.imread(test_char_image)\n",
    "        #print('img', img)\n",
    "        #img = cv2.imread('C:\\\\Users\\\\Administrator\\\\OCR\\\\Final\\\\04-Recognition\\\\characters\\\\2.png')\n",
    "\n",
    "        sorted_ctrs = char_preprocessing_step_1(img)\n",
    "        #print('sorted_ctrs', sorted_ctrs)\n",
    "        new_sorted_ctrs = char_preprocessing_step_2(sorted_ctrs,img)\n",
    "        print('new_sorted_ctrs', new_sorted_ctrs)\n",
    "        temp_max_yh,temp_min_y = char_preprocessing_step_3(new_sorted_ctrs) #normalize height\n",
    "        print('temp_max_yh', temp_max_yh)\n",
    "        print('temp_min_y', temp_min_y)\n",
    "        char_image,char_image_nh = char_preprocessing_step_4(img,new_sorted_ctrs,temp_max_yh,temp_min_y)\n",
    "\n",
    "        #print('Q1_', Q1_)\n",
    "        #print('Q3_', Q3_)\n",
    "        #print('char_image[0]', char_image)\n",
    "        #print('char_image_nh[0]', char_image_nh)\n",
    "        text_char = char_detection(char_image[0],char_image_nh[0],dictionar,Q1_,Q3_)\n",
    "        #print('text_char', text_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
